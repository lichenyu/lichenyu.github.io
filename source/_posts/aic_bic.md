title: AIC BIC
date: 2019/10/12
categories:
- Data Analysis
tags:
- Algorithm
---


模型选择问题是在“模型复杂度”与“模型对数据集描述能力”（即似然函数）之间寻求最佳平衡。
常用的AIC、BIC，**信息准则 = 复杂度惩罚 + 精度惩罚**，值越小越好。
复杂度惩罚：对应“参数数量”、“训练数据量”，数值变大表明模型复杂度增加，容易过拟合
精度惩罚：对应“负log-似然函数”，数值变大表明似然函数降低，模型对数据集的描述能力下降


## AIC

Akaike Information Criterion

$$
AIC = 2k - 2\ln(L)
$$

$k$为参数数量，$L$为似然函数。

当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上式第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。一般而言，当模型复杂度提高（$k$增大）时，似然函数$L$也会增大，从而使$AIC$变小，但是$k$过大时，似然函数增速减缓，导致$AIC$增大，模型过于复杂容易造成过拟合现象。目标是选取$AIC$最小的模型，$AIC$不仅要提高模型拟合度（极大似然），而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。

回归问题计算方法：

$$
AIC = 2k + n\ln(RSS/n)
$$

$n$为样本数量，$RSS$为残差平方和（or SSE, Sum of Squared Errors）。


## BIC

Bayesian Information Criterion

$$
BIC = \ln(n)k - 2\ln{(L)}
$$

$n$为样本数量，$k$为参数数量，$L$为似然函数。

$\ln(n)k$惩罚项在维数$k$过大且训练样本数$n$相对较少的情况下，可以有效避免出现维度灾难现象。
与AIC相似，用于模型选择。训练模型时，增加参数数量，也就是增加模型复杂度，会增大似然函数，但是也会导致过拟合现象，针对该问题，AIC和BIC均引入了与模型参数个数相关的惩罚项，BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。

回归问题计算方法：

$$
BIC = \ln(n)k + n\ln(RSS/n)
$$


$AIC$和$BIC$的公式中后半部分是一样的，前半部分是惩罚项，当$n \ge 8n \ge 8$时，$k\ln(n) \ge 2k kln(n)\ge 2k$，所以$BIC$相比$AIC$在大数据量时对模型参数惩罚得更多，导致BIC更倾向于选择参数少的简单模型。
